# Прочитанные Статьи

|Дата прочтения|Название|Краткое содержание|
|---|---|---|
|10.12.2021|Multi-Domain Dialogue State Tracking based on State Graph ([link](https://arxiv.org/pdf/2010.11137.pdf))|Dialogue state tracking (DST) with dependency on previous dialogue state and slots generation on inference|
| - | Structured Attention for Unsupervised Dialogue Structure Induction ([link]https://arxiv.org/abs/2009.08552) | Inducing a meaningful structural representation from one or a set of dialogues is a crucial but challenging task in computational linguistics. Advancement made in this area is critical for dialogue system design and discourse analysis. It can also be extended to solve grammatical inference. In this work, we propose to incorporate structured attention layers into a Variational Recurrent Neural Network (VRNN) model with discrete latent states to learn dialogue structure in an unsupervised fashion. Compared to a vanilla VRNN, structured attention enables a model to focus on different parts of the source sentence embeddings while enforcing a structural inductive bias. Experiments show that on two-party dialogue datasets, VRNN with structured attention learns semantic structures that are similar to templates used to generate this dialogue corpus. While on multi-party dialogue datasets, our model learns an interactive structure demonstrating its capability of distinguishing speakers or addresses, automatically disentangling dialogues without explicit human annotation.|
| - | TSCAN : Dialog Structure discovery using SCAN ([link] https://arxiv.org/abs/2107.06426) | Can we discover dialog structure by dividing utterances into labelled clusters. Can these labels be generated from the data. Typically for dialogs we need an ontology and use that to discover structure, however by using unsupervised classification and self-labelling we are able to intuit this structure without any labels or ontology. In this paper we apply SCAN (Semantic Clustering using Nearest Neighbors) to dialog data. We used BERT for pretext task and an adaptation of SCAN for clustering and self labeling. These clusters are used to identify transition probabilities and create the dialog structure. The self-labelling method used for SCAN makes these structures interpretable as every cluster has a label. As the approach is unsupervised, evaluation metrics is a challenge, we use statistical measures as proxies for structure quality |

# Конспекты 

--Тут будут конспекты важных статей--
